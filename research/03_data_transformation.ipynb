{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLOPS\\\\ML-Approach-for-Predict-Cancellation-Prevent-Loss-with-MLflow\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLOPS\\\\ML-Approach-for-Predict-Cancellation-Prevent-Loss-with-MLflow'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: str\n",
    "    preprocessing_data : str\n",
    "    train: Path\n",
    "    test: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = CONFIG_FILE_PATH,      \n",
    "                 schema_filepath = SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path= config.data_path,\n",
    "            preprocessing_data = config.preprocessing_data,\n",
    "            train = config.train,\n",
    "            test = config.test\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from src.utils.logger import logging\n",
    "from src.utils.exception import CustomException\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config=DataTransformationConfig):\n",
    "        self.config = config \n",
    "    \n",
    "    \n",
    "    def save_preprocessing_data(self):\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.data_path)\n",
    "            df[\"booking status\"] = df[\"booking status\"].apply(lambda x : 1 if x=='Not_Canceled' else 0) \n",
    "\n",
    "            df = df[~df[\"date of reservation\"].str.contains(\"-\")]\n",
    "\n",
    "            df[\"date of reservation\"] = pd.to_datetime(df[\"date of reservation\"])\n",
    "            df[\"month\"] = df[\"date of reservation\"].dt.month\n",
    "\n",
    "            df.drop(['Booking_ID','date of reservation'], axis=1, inplace=True)\n",
    "\n",
    "            df.to_csv(self.config.preprocessing_data, index=False, header=True)\n",
    "            logging.info(\"Saving pre processing data\")\n",
    "\n",
    "            return \"Preprocessing data saved successfully\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"Error occured in saving preprocess data\")\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "\n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        try:\n",
    "            self.save_preprocessing_data()\n",
    "\n",
    "            df = pd.read_csv(self.config.preprocessing_data)\n",
    "            X = df.drop('booking status',axis=1)\n",
    "            y = df['booking status']\n",
    "\n",
    "            num_feature = X.select_dtypes(exclude=\"object\").columns \n",
    "            cat_feature = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "            numeric_transformer = StandardScaler()\n",
    "            oh_transformer = OneHotEncoder()\n",
    "\n",
    "            data_transformer = ColumnTransformer(\n",
    "                [\n",
    "                    (\"OneHotEncoder\", oh_transformer, cat_feature),\n",
    "                    (\"StandardScaler\", numeric_transformer, num_feature),        \n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            preprocessor = Pipeline(steps=[(\"data_transformer\", data_transformer)])\n",
    "\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Error in creating data transformation object: {e}\")\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "\n",
    "\n",
    "    def train_test_split(self):\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.preprocessing_data)\n",
    "            logging.info(\"Reading dataset as dataframe\")\n",
    "\n",
    "            logging.info(\"Initiate splitting dataset as train & test set\")\n",
    "            train_set, test_set = train_test_split(df)\n",
    "\n",
    "            train_set.to_csv(\n",
    "                os.path.join(self.config.root_dir,\"train.csv\"), index=False\n",
    "            )\n",
    "\n",
    "            test_set.to_csv(\n",
    "                os.path.join(self.config.root_dir,\"test.csv\"), index=False\n",
    "            )\n",
    "\n",
    "            logging.info(\"Dataset splitted into train and test set\")\n",
    "            logging.info(f\"{train_set.shape}\")\n",
    "            logging.info(f\"{test_set.shape}\")\n",
    "\n",
    "            return (\n",
    "                self.config.train,\n",
    "                self.config.test\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info(\"Error in splitting train and test set\")\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "\n",
    "    def initiate_data_transformation(self, train_path, test_path):\n",
    "        try:\n",
    "            train_set = pd.read_csv(train_path)\n",
    "            test_set = pd.read_csv(test_path)\n",
    "            logging.info(\"Reading train and test dataset completed\")\n",
    "\n",
    "            logging.info(\"Obtaining preprocessor object\")\n",
    "\n",
    "            preprocessor_obj =  self.get_data_transformer_object() \n",
    "\n",
    "            target_feature = \"booking status\"\n",
    "            \n",
    "            independent_feature = list(['number of adults', 'number of children', 'number of weekend nights',\n",
    "            'number of week nights', 'type of meal', 'car parking space',\n",
    "            'room type', 'lead time', 'market segment type', 'repeated', 'P-C',\n",
    "            'P-not-C', 'average price', 'special requests', 'month'])\n",
    "            \n",
    "            logging.info(\"Dropping target feature from train and test dataframe\")\n",
    "            input_train_df = train_set.drop(columns=[target_feature], axis=1)\n",
    "            target_train_df = train_set[target_feature]\n",
    "\n",
    "            input_test_df = test_set.drop(columns=[target_feature], axis=1)\n",
    "            target_test_df = test_set[target_feature]\n",
    "\n",
    "            logging.info(\"Applying preprocessor object on training and test dataframe\")\n",
    "            \n",
    "            train_df = preprocessor_obj.fit_transform(input_train_df)\n",
    "            test_df = preprocessor_obj.transform(input_test_df)\n",
    "            \n",
    "            logging.info(\"Successfully applied preprocessor object on train and test data\")\n",
    "\n",
    "            train_arr = np.c_[train_df, np.array(target_train_df)]\n",
    "            test_arr = np.c_[test_df, np.array(target_test_df)]\n",
    "            logging.info(\"Returning train and test array\")\n",
    "            \n",
    "            logging.info(\"Saving train and test set in numpy file\")\n",
    "            np.save(os.path.join(self.config.root_dir,\"train_arr.npy\"), train_arr)\n",
    "            np.save(os.path.join(self.config.root_dir,\"test_arr.npy\"), test_arr)\n",
    "\n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"Error occured in data transformation\")\n",
    "            raise CustomException(e,sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    preprocessor = data_transformation.get_data_transformer_object()\n",
    "    train_path,test_path = data_transformation.train_test_split()\n",
    "    train_arr, test_arr = data_transformation.initiate_data_transformation(train_path,test_path)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"artifacts/data_transformation/test_arr.npy\"\n",
    "n = np.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9062, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9062, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y= n[:,-1]\n",
    "x = n[:, :-1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.30033044, -0.26057114, -0.92627015, -0.14534151,\n",
       "        -0.1806325 ,  1.0989402 , -0.16149425, -0.06000587, -0.08872295,\n",
       "        -0.50567843, -0.78614507,  0.18560467,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.30033044, -0.26057114, -0.92627015, -0.85792117,\n",
       "        -0.1806325 ,  1.55187113, -0.16149425, -0.06000587, -0.08872295,\n",
       "         0.1367181 , -0.78614507,  0.51101733,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.30033044, -0.26057114, -0.92627015, -0.14534151,\n",
       "        -0.1806325 , -0.5385793 , -0.16149425, -0.06000587, -0.08872295,\n",
       "        -0.04886312, -0.78614507,  0.18560467,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
